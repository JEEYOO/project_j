import pandas as pd
import lightgbm as lgbm                 #new 

from google.colab import drive
drive.mount('/content/drive')

train = pd.read_csv('drive/MyDrive/Colab_Notebooks/wine/data/train.csv') #index_col='index'            index 인 column 을 미리 말해서 숫자 취급한다

test = pd.read_csv('drive/MyDrive/Colab_Notebooks/wine/data/test.csv')

print(train.shape)
print(test.shape)

train.info()

train.isnull().sum()

train.describe()

train.columns #전체 column 리스트 뽑기 


columns = ['fixed acidity', 'volatile acidity', 'citric acid',
       'residual sugar', 'chlorides', 'free sulfur dioxide',
       'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol'] #수치형 data만 남겨두기 

trash_bin = ['index', 'quality','type']

import seaborn
import matplotlib.pyplot as pyp

train1 = train

#일단 하나에 대해서

seaborn.displot(train1['fixed acidity'])
#pyp.show()

#모든 col에 대해서 
'''
for co1 in columns:
'''


#모든 col에 대해서 

for co1 in columns:
    seaborn.distplot(train1[co1]) #함수 
    print('column name :', co1)
    pyplot.show()
#pH 처럼 Standard Deviation 모양으로 중간이 봉긋해야 좋은 Example


from sklearn.preprocessing import MinMaxScaler

#MinMax scaling 할 대상들
scaler_cols = {'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide','density'}

print("MinMax 前")
for co1 in scaler_cols:
    seaborn.distplot(train1[co1]) #함수 
    print('column name :', co1)
    pyplot.show()


for colu in scaler_cols :
    scalerM = MinMaxScaler()
    scalerM.fit(train1[[colu]])
    train1[colu] = scalerM.transform(train1[[colu]]) #괄호2개

print("MinMax 後")

for co1 in scaler_cols:
    seaborn.distplot(train1[co1]) #함수 
    print('column name :', co1)
    pyplot.show()

# 똑같은디? 아 전부 0.0~1.0 으로 만든건가 ㅇㅇ

train[['type']] # 적용전


test1 = test

train_hot = pandas.get_dummies(train1)
test_hot = pandas.get_dummies(test1)

train_hot #그냥 자동으로 type_값 이상태로 바뀌어버림

train_hot[['type_red', 'type_white']]

from sklearn.ensemble import RandomForestClassifier

xx = train_hot.drop(['index', 'quality'], axis=1) #첫번째, 두번째 columns
yy = train_hot['quality'] 

# 모델 정의 
modelW = RandomForestClassifier() 
#이런건 그냥 model 이라 하는 것도 괜찮은듯 

modelW.fit(xx,yy)

test_hot # modeling 전 어느 column 이 쓸모없는지 확인하기 

test_hotM = test_hot.drop('index', axis=1)

# predict() 메소드 이용해서 결과값 예측
prediction = modelW.predict(test_hotM)



#튜닝

from sklearn.model_selection import GridSearchCV

modelT = RandomForestClassifier(random_state = 2021)

#params = { } 하기 전에,   어느 것을 튜닝할지 아는 방법

RandomForestClassifier()


params = { 
       'max_depth' : [None, 3,5,10],
       'n_estimators' : [50,100,200,300],
       'max_samples' : [None, 3,5,10]
}

grid_cv = GridSearchCV(modelT, param_grid = params, cv=10)   #10하면 그러함 
grid_cv.fit(xx,yy) #시간 많이 걸림

grid_cv.best_estimator_

grid_cv.best_score_

pred = grid_cv.predict(test_hotM)

submission['quality'] = pred
submission.to_csv('submission_wine2.csv', index = False)


